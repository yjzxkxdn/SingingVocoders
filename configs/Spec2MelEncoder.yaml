data_input_path: [wav]
data_out_path: [out]
val_num: 2
return_type: "mel+linear"

pe: 'parselmouth' # 'parselmouth' or 'harvest'
f0_min: 65
f0_max: 1100
aug_min: 0.9
aug_max: 1.4
aug_num: 1

binary_data_dir: null
binarization_args:
  num_workers: 8
  shuffle: true

DataIndexPath: data
valid_set_name: valid
train_set_name: train


volume_aug: true
volume_aug_prob: 0.5


mel_vmin: -6. #-6.
mel_vmax: 1.5


audio_sample_rate: 44100
audio_num_mel_bins: 128
hop_size: 512            # Hop size.
fft_size: 2048           # FFT size.
win_size: 2048           # FFT size.
fmin: 40
fmax: 16000
fmax_for_loss: null
crop_mel_frames: 32

kl_weight: 0

# global constants


# neural networks

model_args:
  inter_channels: 128    # 和mel_channels一样
  resblock: "2"
  resblock_kernel_sizes: [3,5]
  resblock_dilation_sizes: [[3,5],[3,5]]
  downsample_rates: [1,1]
  downsample_kernel_sizes: [5,5]
  downsample_channels: [1025,512,256]

# training

task_cls: training.spec2melEncoder_task.Spec2MelEncoder


optimizer_args:
  optimizer_cls: torch.optim.AdamW
  lr: 0.00001
  beta1: 0.8
  beta2: 0.99
  weight_decay: 0


lr_scheduler_args:
  scheduler_cls: lr_scheduler.scheduler.WarmupLR
  warmup_steps: 5000
  min_lr: 0.00001

clip_grad_norm: 1
accumulate_grad_batches: 1
sampler_frame_count_grid: 6
ds_workers: 4
dataloader_prefetch_factor: 2

batch_size: 15



num_valid_plots: 100
log_interval: 100
num_sanity_val_steps: 2  # steps of validation at the beginning
val_check_interval: 2000
num_ckpt_keep: 5
max_updates: 100000
permanent_ckpt_start: 200000
permanent_ckpt_interval: 40000

###########
# pytorch lightning
# Read https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api for possible values
###########
pl_trainer_accelerator: 'auto'
pl_trainer_devices: 'auto'
pl_trainer_precision: '32-true'
#pl_trainer_precision: 'bf16' #please do not use bf 16
pl_trainer_num_nodes: 1
pl_trainer_strategy: 
  name: auto
  process_group_backend: nccl
  find_unused_parameters: true
nccl_p2p: true
seed: 114514
